{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import jit \n",
    "from jax.flatten_util import ravel_pytree\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import interpax\n",
    "\n",
    "from adoptODE import train_adoptODE, simple_simulation, dataset_adoptODE\n",
    "from mechanics import *\n",
    "from data_reading import *\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% |#                                                                       |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Reading data...\n",
      "shape of data:  (2000, 2, 101, 101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  3% |##                                                                      |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (2000, 2, 101, 101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  2% |#                                                                       |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (1, 2000, 100, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "l_a = 0.8876\n",
    "t=0\n",
    "true_params = {'k_g':1, 'l_g':1,'eta':.5,'k_a':1,'k_p':1,'l_p':1}\n",
    "\n",
    "N = 0\n",
    "size = 100\n",
    "mode = \"chaos\"\n",
    "\n",
    "\"\"\"\n",
    "    Reads in necessary parameters from config.ini\n",
    "\"\"\"\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "N,size,[] = read_config([])\n",
    "\n",
    "print(\"Reading data...\")\n",
    "x_temp = read_vector(\"../data/SpringMassModel/x.csv\",(N,2,size+1,size+1))\n",
    "x_cm_temp = read_vector(\"../data/SpringMassModel/x_cm.csv\",(N,2,size+1,size+1))\n",
    "T = read_scalar(\"../data/SpringMassModel/T.csv\",(1,N,size,size))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_system(**kwargs_sys):\n",
    "\n",
    "    #bounds for parameters\n",
    "    nu_min, nu_max = kwargs_sys['nu_min'], kwargs_sys['nu_max']\n",
    "    m_min, m_max = kwargs_sys['m_min'], kwargs_sys['m_max']\n",
    "    l_g_min, l_g_max = kwargs_sys['l_g_min'], kwargs_sys['l_g_max']\n",
    "    l_p_min, l_p_max = kwargs_sys['l_p_min'], kwargs_sys['l_p_max']\n",
    "    k_g_min, k_g_max = kwargs_sys['k_g_min'], kwargs_sys['k_g_max']\n",
    "    k_a_min, k_a_max = kwargs_sys['k_a_min'], kwargs_sys['k_a_max']\n",
    "    k_p_min, k_p_max = kwargs_sys['k_p_min'], kwargs_sys['k_p_max']\n",
    "    eta_min, eta_max = kwargs_sys['eta_min'], kwargs_sys['eta_max']\n",
    "\n",
    "    # Interpolated params and coresponding time ,\n",
    "    x_cm_arr = kwargs_sys['x_cm']\n",
    "    x_j_arr = kwargs_sys['x_j']\n",
    "    l_a_arr = kwargs_sys['l_a']\n",
    "    \n",
    "\n",
    "    def gen_y0():\n",
    "\n",
    "        #takes initial conditions from kwargs(data)\n",
    "        x1_0 = kwargs_sys['x1_0']\n",
    "        x2_0 = kwargs_sys['x2_0']\n",
    "        y1_0 = kwargs_sys['y1_0']\n",
    "        y2_0 = kwargs_sys['y2_0']\n",
    "\n",
    "        return {'x1':x1_0, 'x2':x2_0, 'y1':y1_0, 'y2':y2_0}\n",
    "\n",
    "    def gen_params():\n",
    "\n",
    "        nu = nu_min + (nu_max - nu_min) * np.random.rand()\n",
    "        m = m_min + (m_max - m_min) * np.random.rand()\n",
    "\n",
    "        l_g = l_g_min + (l_g_max - l_g_min) * np.random.rand()\n",
    "        l_p = l_p_min + (l_p_max - l_p_min) * np.random.rand()\n",
    "\n",
    "        k_g = k_g_min + (k_g_max - k_g_min) * np.random.rand()\n",
    "        k_a = k_a_min + (k_a_max - k_a_min) * np.random.rand()\n",
    "        k_p = k_p_min + (k_p_max - k_p_min) * np.random.rand()\n",
    "        \n",
    "        eta = eta_min + (eta_max - eta_min) * np.random.rand()\n",
    "\n",
    "        return {'nu':nu,'m':m,'l_g':l_g,'l_p':l_p,'k_g':k_g, 'k_a':k_a,'k_p':k_p, 'eta':eta}, {}, {}\n",
    "\n",
    "        \n",
    "    @jit\n",
    "    def eom(xy, t, params, iparams, exparams):\n",
    "        x = jnp.array([xy['x1'], xy['x2']])\n",
    "        # get interpolated parameters at corresponding time\n",
    "        x_cm = t_to_value_4p(x_cm_arr,t_interp,t,N_interp)\n",
    "        x_j = t_to_value_4p(x_j_arr,t_interp,t,N_interp)\n",
    "        l_a = t_to_value_1p(l_a_arr,t_interp,t,N_interp)\n",
    "\n",
    "        #initialize total force\n",
    "        f = total_force(x, x_j, x_cm, l_a, t, params)\n",
    "\n",
    "        #initialize eom\n",
    "        dx1 = xy['y1']\n",
    "        dx2 = xy['y2']\n",
    "        dy1 = 1/params['m'] * (f[1] - params['nu'] * xy['y1'])\n",
    "        dy2 = 1/params['m'] * (f[2] - params['nu'] * xy['y2'])\n",
    "\n",
    "        return {'x1':dx1, 'x2':dx2, 'y1':dy1, 'y2':dy2}\n",
    "\n",
    "    @jit\n",
    "    def loss(xy, params, iparams, exparams, targets):\n",
    "        \n",
    "        x1 = xy['x1']\n",
    "        x2 = xy['x2']\n",
    "        t_x1 = targets['x1']\n",
    "        t_x2 = targets['x2']\n",
    "        return jnp.mean((x1-t_x1)**2 + (x2-t_x2)**2)\n",
    "\n",
    "    return eom, loss, gen_params, gen_y0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,size,ls = read_config([\"l_0\",\"c_a\",\"k_ij\",\"k_j\",\"k_a\",\"m\",\"c_damp\",\"n_0\",\"delta_t_m\",\"it_m\"])\n",
    "l_0, c_a, k_g0, k_p0, k_a0, m0, nu0, eta0, delta_t_m, it_m = ls\n",
    "l_a0,l_p0,l_g0 = l_0, l_0, l_0\n",
    "\n",
    "delta_t = delta_t_m * it_m\n",
    "t_evals = jnp.linspace(0,2000*delta_t,2000)\n",
    "N_interp = 50\n",
    "\n",
    "x_i,x_j,x_cm,l_a = shape_input_for_adoptode(x_temp, x_cm_temp,T,50,50) #the last two variables define the cell in the grid \n",
    "t_interp, x_cm_interp = interpolate_x(x_cm,t_eval,N_interp)\n",
    "t_interp, x_j_interp = interpolate_x(x_j,t_eval,N_interp)\n",
    "t_interp, l_a_interp = interpolate_scalar(l_a,t_eval,N_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_sys = { \n",
    "    'nu_min': nu0 - nu0 * 0.1,'nu_max': nu0 + nu0 * 0.1,\n",
    "    'm_min': m0 - m0 * 0.1,'m_max' : m0 + m0 * 0.1,\n",
    "    'l_g_min': l_g0 - l_g0 * 0.1,'l_g_max': l_g0 + l_g0 * 0.1,\n",
    "    'l_p_min': l_p0 - l_p0 * 0.1,'l_p_max': l_p0 + l_p0 * 0.1,\n",
    "    'k_g_min': k_g0 - k_g0 * 0.1,'k_g_max': k_g0 + k_g0 * 0.1,\n",
    "    'k_p_min': k_p0 - k_p0 * 0.1,'k_p_max': k_p0 + k_p0 * 0.1,\n",
    "    'k_a_min': k_a0 - k_a0 * 0.1,'k_a_max': k_a0 + k_a0 * 0.1,\n",
    "    'eta_min': eta0 - eta0 * 0.1,'eta_max': eta0 + eta0 * 0.1,\n",
    "    't_interp': t_interp,\n",
    "    'N_interp': N_interp,\n",
    "    'x_cm':x_cm_interp,\n",
    "    'x_j':x_j_interp,\n",
    "    'l_a':l_a_interp,\n",
    "    'x1_0':x_i[0,0],\n",
    "    'x2_0':x_i[0,1],\n",
    "    'y1_0':(x_i[1,0]-x_i[0,0])/delta_t,\n",
    "    'y2_0':(x_i[1,1]-x_i[0,1])/delta_t,\n",
    "    'N_sys': 1\n",
    "}\n",
    "kwargs_adoptODE = {'lr':3e-2, 'epochs':200,'N_backups':5}\n",
    "dataset = simple_simulation(define_system,\n",
    "                                t_evals,\n",
    "                                kwargs_sys,\n",
    "                                kwargs_adoptODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true parameters used to generate the data:  {'nu': 14.097883056815917, 'm': 0.9028675597243122, 'l_g': 1.0576632539674002, 'l_p': 0.9799187570086381, 'k_g': 13.111669781834362, 'k_a': 9.231034699741615, 'k_p': 1.8033307539106551, 'eta': 0.5093111325918764}\n",
      "The initial gues of parameters for the recovery:  {'nu': 14.97593783967928, 'm': 1.0560865405432396, 'l_g': 0.9896920767397941, 'l_p': 1.0556434480443577, 'k_g': 12.330466232269101, 'k_a': 8.805897644297735, 'k_p': 2.1763872455295767, 'eta': 0.48305348762893174}\n"
     ]
    }
   ],
   "source": [
    "print('The true parameters used to generate the data: ', dataset.params)\n",
    "print('The initial gues of parameters for the recovery: ', dataset.params_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000:  Loss: 3.6e-01,  Params Err.: 1.3e+00, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 020:  Loss: 1.1e-02,  Params Err.: 1.2e+00, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 040:  Loss: 1.1e-02,  Params Err.: 1.1e+00, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 060:  Loss: 7.2e-03,  Params Err.: 1.1e+00, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 080:  Loss: 5.7e-03,  Params Err.: 1.0e+00, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 100:  Loss: 4.6e-03,  Params Err.: 9.5e-01, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 120:  Loss: 4.0e-03,  Params Err.: 9.1e-01, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 140:  Loss: 3.4e-03,  Params Err.: 8.8e-01, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 160:  Loss: 3.2e-03,  Params Err.: 8.5e-01, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 180:  Loss: 2.2e-03,  Params Err.: 8.3e-01, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 199:  Loss: 2.0e-03,  Params Err.: 8.1e-01, y0 error: 0.0e+00, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "True params:  {'nu': 14.097883056815917, 'm': 0.9028675597243122, 'l_g': 1.0576632539674002, 'l_p': 0.9799187570086381, 'k_g': 13.111669781834362, 'k_a': 9.231034699741615, 'k_p': 1.8033307539106551, 'eta': 0.5093111325918764}\n",
      "Found params:  {'eta': Array(0.50232005, dtype=float32), 'k_a': Array(8.735692, dtype=float32), 'k_g': Array(12.648676, dtype=float32), 'k_p': Array(2.101373, dtype=float32), 'l_g': Array(0.8340413, dtype=float32), 'l_p': Array(1.1777796, dtype=float32), 'm': Array(0.87691593, dtype=float32), 'nu': Array(14.229173, dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "_ = train_adoptODE(dataset)\n",
    "print('True params: ', dataset.params)\n",
    "print('Found params: ', dataset.params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_array = jnp.full((1, 2000), jnp.nan)\n",
    "kwargs_adoptODE = {'lr':3e-2, 'epochs':200,'N_backups':5}\n",
    "targets = {\"x1\":x_i[:,0].reshape((1,2000)),'x2':x_i[:,1].reshape((1,2000)),'y1':nan_array,'y2':nan_array}\n",
    "dataset2 = dataset_adoptODE(define_system,\n",
    "                                targets,\n",
    "                                t_evals,\n",
    "                                kwargs_sys,\n",
    "                                kwargs_adoptODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000:  Loss: nan,  Params Err.: nan, y0 error: nan, Params Norm: 2.1e+01, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Gradients resulted to nans. Maybe try the back_check function to see is your backward pass is instable. In that case it can help to increase the number of Backups ('N_backups') used in between time points.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_adoptODE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound params: \u001b[39m\u001b[38;5;124m'\u001b[39m, dataset2\u001b[38;5;241m.\u001b[39mparams_train)\n",
      "File \u001b[0;32m/data.bmp/lbremer/Master_thesis/adoptODE_smmodell/.ad_ode_venv3/lib/python3.9/site-packages/adoptODE/Framework.py:1020\u001b[0m, in \u001b[0;36mtrain_adoptODE\u001b[0;34m(dataset, print_interval, save_interval, print_both_losses)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m   1008\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step), loss_string,\n\u001b[1;32m   1009\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParams Err.: \u001b[39m\u001b[38;5;132;01m{:.1e}\u001b[39;00m\u001b[38;5;124m, y0 error: \u001b[39m\u001b[38;5;132;01m{:.1e}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1014\u001b[0m                pytree_norm(iparams_true, get_iparams(opt_state_ip)),\n\u001b[1;32m   1015\u001b[0m                pytree_norm(get_iparams(opt_state_ip))), act_loss_string)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([\n\u001b[1;32m   1017\u001b[0m     x\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree_util\u001b[38;5;241m.\u001b[39mtree_flatten(\n\u001b[1;32m   1018\u001b[0m         tree_util\u001b[38;5;241m.\u001b[39mtree_map(jnp\u001b[38;5;241m.\u001b[39misnan, (grads, grads_ip, grads_y0)))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1019\u001b[0m ]):\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradients resulted to nans. Maybe try the back_check function \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto see is your backward pass is instable. In that case it can help \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto increase the number of Backups (\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mN_backups\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) used in between \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime points.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1025\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m opt_update(step, grads, opt_state)\n\u001b[1;32m   1026\u001b[0m opt_state_y0 \u001b[38;5;241m=\u001b[39m opt_update_y0(step, grads_y0, opt_state_y0)\n",
      "\u001b[0;31mException\u001b[0m: Gradients resulted to nans. Maybe try the back_check function to see is your backward pass is instable. In that case it can help to increase the number of Backups ('N_backups') used in between time points."
     ]
    }
   ],
   "source": [
    "_ = train_adoptODE(dataset2)\n",
    "\n",
    "print('Found params: ', dataset2.params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_a0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".adoptodevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
